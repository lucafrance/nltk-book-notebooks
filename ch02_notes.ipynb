{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2f15db1-6c0e-48d4-90bf-9e22227c0195",
   "metadata": {},
   "source": [
    "# 2. Accessing Text Corpora and Lexical Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26459243-e76a-4cbb-abb6-0c21b525e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f391ca-e0b8-41b4-b47d-190a6749b600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8a35fec-0d91-4cb1-b412-c7da67d8cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb42ccd2-fb1f-4258-8797-2446c1cc884a",
   "metadata": {},
   "source": [
    "## Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd334b95-635d-4af0-bc75-422f28a565ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a271fca-953b-41ee-baf9-a4d4f1f4ba19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e56e0-8516-4d98-bfda-9a880fdfeef6",
   "metadata": {},
   "source": [
    "Your Turn: Choose a different section of the Brown Corpus, and adapt the previous example to count a selection of wh words, such as what, when, where, who, and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3f734f8-c7e6-48b5-896f-175a4355cedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what: 58 when: 68 where: 48 who: 77 why: 6 "
     ]
    }
   ],
   "source": [
    "gov_text = brown.words(categories=\"government\")\n",
    "fdist = nltk.FreqDist(w.lower() for w in gov_text)\n",
    "wh_words = [\"what\", \"when\", \"where\", \"who\", \"why\"]\n",
    "for w in wh_words:\n",
    "    print(f\"{w}: {fdist[w]}\", end = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b1594f-3c69-4f37-972b-42349fdb48f5",
   "metadata": {},
   "source": [
    "## Reuters Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d7d3b9f-868a-4b37-b4e0-aaf5cb672c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30bb4a5f-13ad-479a-bf9b-13eded5a85f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_LazyCorpusLoader__args',\n",
       " '_LazyCorpusLoader__kwargs',\n",
       " '_LazyCorpusLoader__load',\n",
       " '_LazyCorpusLoader__name',\n",
       " '_LazyCorpusLoader__reader_cls',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_unload',\n",
       " 'subdir']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7aba2d-ef66-4eba-bc64-f4883542d115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
