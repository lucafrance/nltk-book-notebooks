{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77481fd0-66d9-4581-a004-42eb7b9d1c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed18679-cc30-4e81-bb8a-5392e57a5496",
   "metadata": {},
   "source": [
    "#### 1. Define a string `s = 'colorless'`. Write a Python statement that changes this to \"colourless\" using only the slice and concatenation operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d1c30f-664a-4700-a597-a1ab9c7cb87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'colourless'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"colorless\"\n",
    "s = s[:4] + \"u\" + s[4:]\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f7628-f5b6-4402-8b4f-ffdf2a511b93",
   "metadata": {},
   "source": [
    "#### 2. We can use the slice notation to remove morphological endings on words. For example, `'dogs'[:-1]` removes the last character of `dogs`, leaving `dog`. Use slice notation to remove the affixes from these words (we've inserted a hyphen to indicate the affix boundary, but omit this from your strings): `dish-es`, `run-ning`, `nation-ality`, `un-do`, `pre-heat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d145f7d-2a20-4c71-991e-2d2df2b266d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dish'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"dishes\"[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e7713a-ef3e-41e2-a236-3d7d8a8bfd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"running\"[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a66017ac-2442-4e37-82df-02f2fcf38eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nation'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"nationality\"[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd48017b-cb44-41d0-a94f-bd885b88b642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'un'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"undo\"[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e52cfc94-8cdc-4c0e-8c56-598997398313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pre'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"preheat\"[:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80135646-b2b0-4976-94e2-088dc38a1efa",
   "metadata": {},
   "source": [
    "#### 3. We saw how we can generate an `IndexError` by indexing beyond the end of a string. Is it possible to construct an index that goes too far to the left, before the start of the string?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb5127e-a7c3-4efc-bfdb-c84432c2eec4",
   "metadata": {},
   "source": [
    "Yes, for example with negative indexeses too big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d86b82-e362-4cd5-abeb-108ce11b7a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string index out of range\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    \"ciao\"[-10]\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e778377-4b05-49ae-ac6d-7aa8836f42cd",
   "metadata": {},
   "source": [
    "#### 4. We can specify a \"step\" size for the slice. The following returns every second character within the slice: `monty[6:11:2]`. It also works in the reverse direction: `monty[10:5:-2]` Try these for yourself, then experiment with different step values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db0d10b2-2bca-419b-8421-0834fc7a9c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "monty = 'Monty Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1aaee1af-dea9-4290-adb9-cfbca5a8186a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pto'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[6:11:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "408d758a-6948-4c5b-a050-8ed50860288c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'otP'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[10:5:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d67023-f60d-42a5-9e7e-5bfb7b5c822d",
   "metadata": {},
   "source": [
    "#### 5. What happens if you ask the interpreter to evaluate `monty[::-1]`? Explain why this is a reasonable result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6339d765-8070-437f-8990-838c20d53ed1",
   "metadata": {},
   "source": [
    "I get the whole string, as there are no limit indexeses. The thing is in reverse order, as the step is negative and gives one characther at the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc0c0d54-5193-4617-9b72-24dcdf1b4f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nohtyP ytnoM'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eceda0-f588-4027-abe6-c53fde8dd24f",
   "metadata": {},
   "source": [
    "#### 6. Describe the class of strings matched by the following regular expressions.\n",
    "- a. `[a-zA-Z]+`\n",
    "- b. `[A-Z][a-z]*`\n",
    "- c. `p[aeiou]{,2}t`\n",
    "- d. `\\d+(\\.\\d+)?`\n",
    "- e. `([^aeiou][aeiou][^aeiou])*`\n",
    "- f. `\\w+|[^\\w\\s]+`\n",
    "\n",
    "Test your answers using `nltk.re_show()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e2c5a-0668-404a-b78e-728d9d3bfbc4",
   "metadata": {},
   "source": [
    "Anwsers:\n",
    "- a. All alphabetic words.\n",
    "- b. All alphabetic words starting with a upper case letter and followed by none or lower case letters.\n",
    "- c. All words starting with \"p\", followed by no more than two vowels, followed by \"t\".\n",
    "- d. Any number, whole or decimal.\n",
    "- e. Every three letter words with a consonant, then a vowel, then a consonant.\n",
    "- f. Every alphanumeric word or non-alphanumeric charachter followed by a whitespace charachter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fa4700d-2256-4365-8799-0948ffde4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import udhr\n",
    "text = udhr.raw('English-Latin1')[2060:2850]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e82c39e-5a57-4c9c-a9a8-2f9f471821dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Article} 1 \n",
      "{All} {human} {beings} {are} {born} {free} {and} {equal} {in} {dignity} {and} {rights}. {They} {are} {endowed} {with} {reason} {and} {conscience} {and} {should} {act} {towards} {one} {another} {in} {a} {spirit} {of} {brotherhood}. \n",
      "\n",
      "{Article} 2 \n",
      "{Everyone} {is} {entitled} {to} {all} {the} {rights} {and} {freedoms} {set} {forth} {in} {this} {Declaration}, {without} {distinction} {of} {any} {kind}, {such} {as} {race}, {colour}, {sex}, {language}, {religion}, {political} {or} {other} {opinion}, {national} {or} {social} {origin}, {property}, {birth} {or} {other} {status}. \n",
      "\n",
      "{Furthermore}, {no} {distinction} {shall} {be} {made} {on} {the} {basis} {of} {the} {political}, {jurisdictional} {or} {international} {status} {of} {the} {country} {or} {territory} {to} {which} {a} {person} {belongs}, {whether} {it} {be} {independent}, {trust}, {non}-{self}-{governing} {or} {under} {any} {other} {limitation} {of} {sovereignty}. \n",
      "\n",
      "{Article} 3 \n",
      "{Everyone} {has} {the} {right} {to} {life}, {liberty} {and} {security} {of} {person}.\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(r\"[a-zA-Z]+\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c305a916-911e-4759-bd27-15867864d994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Article} 1 \n",
      "{All} human beings are born free and equal in dignity and rights. {They} are endowed with reason and conscience and should act towards one another in a spirit of brotherhood. \n",
      "\n",
      "{Article} 2 \n",
      "{Everyone} is entitled to all the rights and freedoms set forth in this {Declaration}, without distinction of any kind, such as race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status. \n",
      "\n",
      "{Furthermore}, no distinction shall be made on the basis of the political, jurisdictional or international status of the country or territory to which a person belongs, whether it be independent, trust, non-self-governing or under any other limitation of sovereignty. \n",
      "\n",
      "{Article} 3 \n",
      "{Everyone} has the right to life, liberty and security of person.\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(r\"[A-Z][a-z]*\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71c16ccf-ba4b-49c1-9389-f094ffcb99db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 1 \n",
      "All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood. \n",
      "\n",
      "Article 2 \n",
      "Everyone is entitled to all the rights and freedoms set forth in this Declaration, without distinction of any kind, such as race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status. \n",
      "\n",
      "Furthermore, no distinction shall be made on the basis of the political, jurisdictional or international status of the country or territory to which a person belongs, whether it be independent, trust, non-self-governing or under any other limitation of sovereignty. \n",
      "\n",
      "Article 3 \n",
      "Everyone has the right to life, liberty and security of person.\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(r\"p[aeiou]{,2}t\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7560655d-7c8e-445d-9e4c-7748e8223687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article {1} \n",
      "All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood. \n",
      "\n",
      "Article {2} \n",
      "Everyone is entitled to all the rights and freedoms set forth in this Declaration, without distinction of any kind, such as race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status. \n",
      "\n",
      "Furthermore, no distinction shall be made on the basis of the political, jurisdictional or international status of the country or territory to which a person belongs, whether it be independent, trust, non-self-governing or under any other limitation of sovereignty. \n",
      "\n",
      "Article {3} \n",
      "Everyone has the right to life, liberty and security of person.\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(r\"\\d+(\\.\\d+)?\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dc6000c-ae74-4bab-9712-b693deef8526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}A{}r{ticle }{}1{} {}\n",
      "{}A{}l{}l{} {hum}{}a{}n{} {}b{}e{}i{}n{}g{}s{ ar}{}e{} {bor}{}n{} {}f{}r{}e{}e{ an}{}d{ eq}{}u{}a{}l{ in}{} {dignit}{}y{ an}{}d{} {rig}{}h{}t{}s{}.{} {}T{hey ar}{}e{ endow}{}e{}d{} {wit}{}h{} {}r{}e{}a{son an}{}d{} {con}{}s{}c{}i{}e{}n{ce }{}a{}n{}d{} {}s{}h{}o{}u{}l{}d{ ac}{}t{} {tow}{}a{}r{}d{}s{ on}{}e{ an}{}o{}t{her in a }{}s{pir}{}i{}t{ of}{} {}b{rother}{}h{}o{}o{}d{}.{} {}\n",
      "{}\n",
      "{}A{}r{ticle }{}2{} {}\n",
      "{}E{veryon}{}e{ is entitled}{} {to }{}a{}l{}l{} {}t{he rig}{}h{}t{}s{ an}{}d{} {}f{}r{}e{}e{dom}{}s{} {set}{} {for}{}t{}h{ in}{} {}t{his}{} {Declar}{}a{}t{}i{}o{}n{},{} {wit}{}h{}o{}u{}t{} {distin}{}c{}t{}i{}o{}n{ of an}{}y{} {kin}{}d{},{} {suc}{}h{ as}{} {rac}{}e{},{} {col}{}o{}u{}r{},{} {sex}{},{} {lan}{}g{}u{}a{ge,}{} {rel}{}i{}g{}i{}o{}n{},{} {pol}{}i{tic}{}a{}l{ or other op}{}i{}n{}i{}o{}n{},{} {nat}{}i{}o{nal or}{} {soc}{}i{}a{}l{ or}{}i{gin}{},{} {}p{rop}{}e{}r{}t{}y{},{} {bir}{}t{}h{ or other}{} {}s{tat}{}u{}s{}.{} {}\n",
      "{}\n",
      "{Fur}{}t{hermor}{}e{},{} {no distin}{}c{}t{}i{}o{}n{} {}s{hal}{}l{} {be mad}{}e{ on}{} {}t{he bas}{}i{}s{ of}{} {}t{he pol}{}i{tic}{}a{}l{},{} {jur}{}i{}s{dic}{}t{}i{}o{nal or internat}{}i{}o{nal}{} {}s{tat}{}u{}s{ of}{} {}t{he }{}c{}o{}u{}n{}t{}r{}y{ or}{} {territ}{}o{}r{}y{} {to }{}w{hic}{}h{ a person}{} {bel}{}o{}n{}g{}s{},{} {}w{hether it}{} {be }{}i{}n{dep}{}e{}n{den}{}t{},{} {}t{rus}{}t{},{} {non}{}-{sel}{}f{}-{gov}{}e{}r{nin}{}g{ or under an}{}y{ other}{} {lim}{}i{tat}{}i{}o{}n{ of}{} {sov}{}e{}r{}e{}i{}g{}n{}t{}y{}.{} {}\n",
      "{}\n",
      "{}A{}r{ticle }{}3{} {}\n",
      "{}E{veryon}{}e{} {has}{} {}t{he rig}{}h{}t{} {to lif}{}e{},{} {lib}{}e{}r{}t{}y{ an}{}d{} {sec}{}u{rit}{}y{ of}{} {person}{}.{}\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(r\"([^aeiou][aeiou][^aeiou])*\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fe47093-6f47-4c41-be30-5db139530d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Article} {1} \n",
      "{All} {human} {beings} {are} {born} {free} {and} {equal} {in} {dignity} {and} {rights}{.} {They} {are} {endowed} {with} {reason} {and} {conscience} {and} {should} {act} {towards} {one} {another} {in} {a} {spirit} {of} {brotherhood}{.} \n",
      "\n",
      "{Article} {2} \n",
      "{Everyone} {is} {entitled} {to} {all} {the} {rights} {and} {freedoms} {set} {forth} {in} {this} {Declaration}{,} {without} {distinction} {of} {any} {kind}{,} {such} {as} {race}{,} {colour}{,} {sex}{,} {language}{,} {religion}{,} {political} {or} {other} {opinion}{,} {national} {or} {social} {origin}{,} {property}{,} {birth} {or} {other} {status}{.} \n",
      "\n",
      "{Furthermore}{,} {no} {distinction} {shall} {be} {made} {on} {the} {basis} {of} {the} {political}{,} {jurisdictional} {or} {international} {status} {of} {the} {country} {or} {territory} {to} {which} {a} {person} {belongs}{,} {whether} {it} {be} {independent}{,} {trust}{,} {non}{-}{self}{-}{governing} {or} {under} {any} {other} {limitation} {of} {sovereignty}{.} \n",
      "\n",
      "{Article} {3} \n",
      "{Everyone} {has} {the} {right} {to} {life}{,} {liberty} {and} {security} {of} {person}{.}\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(r\"\\w+|[^\\w\\s]+\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b001361-cd8f-43d1-b54b-15670f11ecda",
   "metadata": {},
   "source": [
    "#### 7. Write regular expressions to match the following classes of strings:\n",
    "- a. A single determiner (assume that *a*, *an*, and *the* are the only determiners).\n",
    "- b. An arithmetic expression using integers, addition, and multiplication, such as `2*3+8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e870228-e044-4c72-81e6-634be973afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = r\"\\b(a|an|the)\\b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "457027de-6983-42e8-959a-83b28d5e4ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import udhr\n",
    "text = udhr.raw('English-Latin1')[2060:2850]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbf51f1b-c17b-4376-abb5-566265a90146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 1 \n",
      "All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in {a} spirit of brotherhood. \n",
      "\n",
      "Article 2 \n",
      "Everyone is entitled to all {the} rights and freedoms set forth in this Declaration, without distinction of any kind, such as race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status. \n",
      "\n",
      "Furthermore, no distinction shall be made on {the} basis of {the} political, jurisdictional or international status of {the} country or territory to which {a} person belongs, whether it be independent, trust, non-self-governing or under any other limitation of sovereignty. \n",
      "\n",
      "Article 3 \n",
      "Everyone has {the} right to life, liberty and security of person.\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(p, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e71d085c-22e7-4a89-beed-8a78d53650ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = r\"[\\s][\\d(+|*)]+\\b[\\s]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b748612d-5b8d-4784-85a2-b2d2d9bb1be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 lorem{ 2+3 }ipsum{ 4+5 }dolor 6*7.2 sit{ 8+9*0 }amet 1+2-3\n"
     ]
    }
   ],
   "source": [
    "s = \"1 lorem 2+3 ipsum 4+5 dolor 6*7.2 sit 8+9*0 amet 1+2-3\"\n",
    "nltk.re_show(p, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c217ff3-dc22-4241-b20f-d3f36665483d",
   "metadata": {},
   "source": [
    "#### 8. Write a utility function that takes a URL as its argument, and returns the contents of the URL, with all HTML markup removed. Use `from urllib import request` and then `request.urlopen('http://nltk.org/').read().decode('utf8')` to access the contents of the URL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c769fd4-175d-46b3-81fd-079a38725070",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee27f2fd-9a61-44e8-aea0-1ea666f97d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_text(url):\n",
    "    html = request.urlopen(url).read().decode(\"utf8\")\n",
    "    return BeautifulSoup(html).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26d2fe23-ff73-4f45-aa3f-ebd2609908c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\nNLTK :: Natural Language Toolkit\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNLTK\\n\\n\\n\\nDocumentation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNLTK Documentation\\n\\nAPI Reference\\nExample Usage\\nModule Index\\nWiki\\nFAQ\\nOpen Issues\\nNLTK on GitHub\\n\\nInstallation\\n\\nInstalling NLTK\\nInstalling NLTK Data\\n\\nMore\\n\\nRelease Notes\\nContributing to NLTK\\nNLTK Team\\n\\n\\n\\n\\n\\n\\nNatural Language Toolkit¶\\nNLTK is a leading platform for building Python programs to work with human la'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_text(\"https://www.nltk.org\")[:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2654529-3624-426e-b71e-bbd89f583792",
   "metadata": {},
   "source": [
    "#### 9. Save some text into a file corpus.txt. Define a function load(f) that reads from the file named in its sole argument, and returns a string containing the text of the file.\n",
    "- a. Use `nltk.regexp_tokenize()` to create a tokenizer that tokenizes the various kinds of punctuation in this text. Use one multi-line regular expression, with inline comments, using the verbose flag `(?x)`.\n",
    "- b. Use `nltk.regexp_tokenize()` to create a tokenizer that tokenizes the following kinds of expression: monetary amounts; dates; names of people and organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "886d20cf-8770-4291-911a-ad8670068152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(f):\n",
    "    return open(f, \"rt\", encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44127b7f-1f25-4f11-b5a3-cb3027d5e863",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load(\"ch02/corpus.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f97a95ca-2f34-40a2-8e34-3c9cd5954007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{';', ':', '.', '...', '%', ')', '(', '/', ',', ']', '?', '[', '!'}\n",
      "[',', '.', '.', '.', ',', '.', '.', '.', ',', '.', ':', ':', '.', '.', ':', '[', ']', '[', ':', ',', ']', ':', '.', '.', '?', '.', '.', '.', '?', '.', '.', '.', '?', '(', ')', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', ';', ',', '.', ',', '.', '.', ',']\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"\"\"(?x)\n",
    "      \\.\\.\\.        # ellipsis\n",
    "    | [!\\?,;\\.:]    # sentence structure\n",
    "    | [()\\[\\]\\{\\}]  # parentheses\n",
    "    | [%&/]         # other symbols                   \n",
    "    \"\"\"\n",
    "tokens = nltk.regexp_tokenize(corpus, pattern)\n",
    "print(set(tokens)) # Check the types to verify easly that the regular expression is working as expected\n",
    "print(tokens[:100]) # Sample, 100 is arbitrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "013c45fc-d08f-4678-9209-896ea791aede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Project', 'The War', 'United States', 'Project Gutenberg', 'United States', 'The War', 'November 27, 2021', 'The Anatomy', 'Lick Observatory', 'Daily\\nTelegraph', 'Horsell Bridge', 'Horsell Common', 'Good Lord', 'Daily Chronicle', 'Astronomical Exchange', 'Chobham\\nRoad', 'Astronomer Royal', 'Lord Hilton', 'Lord\\nHilton', 'Good God', 'Horsell\\nBridge', 'Oriental Terrace', 'Poor Ogilvy', 'The Times', 'Daily Telegraph', 'Major Eden', 'Byfleet Golf', 'Horse Guards', 'Oriental College', 'Maybury\\nHill', 'Oriental College', 'Spotted Dog', 'Maybury Hill', 'Old\\nWoking', 'Maybury Inn', 'Maybury Hill', 'Maybury\\nHill', 'Old Woking', 'Pyrford Church', 'Pyrford Church', 'Maybury Hill', 'Maybury Hill', 'Maybury Hill', 'Street\\nCobham', 'College Arms', 'Spotted Dog', 'College Arms', 'College Arms', 'Maybury Bridge', 'Horsell Common', 'Oriental College', 'My God', 'Horse Artillery', 'Street Cobham', 'Maybury Hill', 'Old Woking', 'General Marvin', 'Shepperton Lock', 'Shepperton\\nChurch', 'Shepperton Church', 'Horsell Common', 'Horsell Common', 'Addlestone Golf', 'Horsell Common', 'Epsom Downs', 'Virginia Water', 'Portsmouth\\nSunday', 'Cardigan Regiment', 'West Surrey', 'Sunday Sun', 'Foundling Hospital', 'Western Company', 'Hampton Court', 'The Martians', 'Richmond Park', 'Salvation\\nArmy', 'Waterloo Road', 'Clock Tower', 'Wellington Street', 'Fleet Street', 'Wellington Street', 'Horsell Common', 'Wellington Street', 'Trafalgar Square', 'West Surrey', 'Westminster Bridge', 'Epsom High', 'Derby Day', 'Oxford\\nStreet', 'Marylebone Road', 'Regent Street', 'Portland Place', 'Albany Street', 'Chalk Farm', 'The Kingston', 'Thames Valley', 'Park Terraces', 'Westbourne Park', 'East Ham', 'Black Smoke', 'Black Smoke', 'The Martians', 'Black Smoke', 'Black Smoke', 'Westminster Bridge', 'Upper Halliford', 'Painshill Park', 'Street Cobham', 'Street Cobham', 'Upper Halliford', 'Richmond Hill', 'Kingston Hill', 'Bushey Park', 'Richmond Park', 'Kingston Hill', 'Cannon Street', 'Bishopsgate Street', 'Liverpool Street', 'Castle Hill', 'Chalk\\nFarm', 'Chalk Farm', 'Haverstock\\nHill', 'Belsize Road', 'Edgware Road', 'High Barnet', 'New Barnet', 'New Barnet', 'Great North', 'East End', 'Chalk Farm', 'Salvation Army', 'The Martians', 'Miss Elphinstone', 'Lord Garrick', 'Lord Garrick', 'Chief Justice', 'Miss Elphinstone', 'Miss Elphinstone', 'Chipping Barnet', 'East Barnet', 'Great Northern', 'Waltham Abbey', 'Chipping Barnet', 'Black Smoke', 'Blackfriars Bridge', 'Tower Bridge', 'Clock Tower', 'Black\\nSmoke', 'Midland Railway', 'Chipping Ongar', 'Primrose Hill', 'Miss Elphinstone', 'Public Supply', 'Waltham Abbey', 'Powder\\nMills', 'Thunder Child', 'Channel Fleet', 'Thunder Child', 'Thunder Child', 'Black Smoke', 'Thunder Child', 'Thunder Child', 'Black Smoke', 'Black Smoke', 'Black Smoke', 'Black Smoke', 'Black Smoke', 'Hampton Court', 'Hampton Court', 'Bushey Park', 'Black Smoke', 'Richmond\\nBridge', 'Black Smoke', 'Kew Lodge', 'Shepperton\\nChurch', 'Professor Howes', 'Pall Mall', 'For God', 'The Martians', 'Putney Common', 'Putney Hill', 'Putney Hill', 'Putney Hill', 'Thomas Lobb', 'New Malden', 'West Hill', 'Wimbledon Common', 'Royal Academy', 'Great God', 'British Museum', 'Putney Hill', 'Putney Hill', 'Regent Street', 'Great God', 'High Street', 'Putney Bridge', 'Walham Green', 'Fulham\\nRoad', 'South Kensington', 'South Kensington', 'Exhibition Road', 'Kensington Gardens', 'Hyde Park', 'Natural\\nHistory', 'Exhibition Road', 'Oxford Street', 'Marble Arch', 'Baker Street', 'Portman Square', 'Baker\\nStreet', 'Park Road', 'Baker Street', 'Primrose Hill', 'Zoological Gardens', 'Wood Road', 'Harrow Road', 'Primrose Hill', 'Albert Road', 'Primrose\\nHill', 'Albert Terrace', 'Langham Hotel', 'Albert Hall', 'Imperial Institute', 'Brompton Road', 'Crystal Palace', 'Primrose Hill', 'Irish Sea', 'The Last', 'Man Left', 'The Last', 'Man Left', 'Wellington Street', 'Waterloo Bridge', 'Daily Mail', 'Clapham Junction', 'Black\\nSmoke', 'Clapham\\nJunction', 'Union Jack', 'Spotted Dog', 'College Arms', 'Moral Ideas', 'Daily\\nChronicle', 'Black Smoke', 'South\\nKensington', 'Natural History', 'Byfleet Road', 'Fleet Street', 'Primrose Hill', 'United States', 'United States', 'General Terms', 'Project\\nGutenberg', 'Project Gutenberg', 'United States', 'Project Gutenberg', 'Project\\nGutenberg', 'Full\\nProject', 'Redistributing Project', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project\\nGutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Literary Archive', 'Project Gutenberg', 'United\\nStates', 'United States', 'United States', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'United States', 'Project Gutenberg', 'United States', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'United States', 'Project Gutenberg', 'Project Gutenberg', 'United States', 'Project\\nGutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project\\nGutenberg', 'Project Gutenberg', 'Plain Vanilla', 'Project Gutenberg', 'Plain\\nVanilla', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Literary Archive', 'Literary Archive', 'Project Gutenberg', 'Archive Foundation', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project\\nGutenberg', 'Project Gutenberg', 'Literary Archive', 'Project Gutenberg', 'Project\\nGutenberg', 'Project Gutenberg', 'Project\\nGutenberg', 'Literary Archive', 'Project\\nGutenberg', 'Project\\nGutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project\\nGutenberg', 'Literary Archive', 'Project Gutenberg', 'Project Gutenberg', 'Literary\\nArchive', 'Project Gutenberg', 'Literary\\nArchive', 'Project Gutenberg', 'Literary Archive', 'Internal\\nRevenue', 'Project Gutenberg', 'Literary\\nArchive', 'Salt Lake', 'Project Gutenberg', 'Literary Archive', '$1', '$5,000', 'United\\nStates', 'United States', 'Project Gutenberg', 'Information About', 'Project Gutenberg', 'Project\\nGutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Project Gutenberg', 'Literary\\nArchive']\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"\"\"(?x)\n",
    "        [£$€]{1}\\s?[\\d\\.,]+                        # monetary amounts \n",
    "      | [A-Z][a-z]+\\s+\\d{1,2},\\s+\\d{4}             # dates\n",
    "      | (?<!\\.\\s)(?<!\\s\\s)[A-Z][a-z]+\\s[A-Z][a-z]+ # names of people and organizations \n",
    "                                                   # two titled words, not preceded by a period or a new paragraph\n",
    "                                                   # using negative lookbehind\n",
    "    \"\"\"\n",
    "tokens = nltk.regexp_tokenize(corpus, pattern)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4adcd-f0b1-474e-8c44-dd4c1f8ab32d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
